# Playing with neural networks

I created this code some time ago with the goal to have little bit of fun with neural networks, and learn about them. 

In here you will find a "mini-library" for creating simple MLPs (Multi Layer Perceptron):

* Xavier weight initializations
* Gradient Descent, Gradient Descent with momentum, RMSProp (Root Mean Square Prod), Adam (Adaptative moment estimation)
* ReLU, Sigmoid
* Quadratic Cost

If you have something cool to share or something you would do differently, let me know, I would love to hear it. :blush:

## Goals

* Have fun (enjoy the process) :sunglasses:
* Get a loose grasp on what makes Neural Networks tick.

## Non-goals

* Become a python master
* Performance
* Accurate models

### Disclaimer
 
This is not necessarily representative on how I would build or make decisions for production applications/solutions. I do these tiny projects for personal enjoyment and to scratch my itchy curious brain, using the little free time I have. 

