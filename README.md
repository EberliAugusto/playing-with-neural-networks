# Playing with neural networks

I created this code some time ago with the goal to have little bit of fun with neural networks, and learn about them. 

In here you will find a "mini-library" for creating simple MLPs (Multi Layer Perceptron):

* Xavier weight initializations
* Gradient Descent, Gradient Descent with momentum, RMSProp (Root Mean Square Prod), Adam (Adaptative moment estimation)
* ReLU, Sigmoid
* Quadratic Cost

## Non-goals

* Learn python
* Performance


